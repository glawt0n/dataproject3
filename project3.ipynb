{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\n",
        "Project 3"
      ],
      "metadata": {
        "id": "0gdC70xxFyc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Fashion-MNIST image classification using sklearn"
      ],
      "metadata": {
        "id": "i9_7SnpMGKDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(len(X_train), -1)\n",
        "X_test  = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "AB136H0PGKq1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "5GAsN-dmHjRM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_configuration(config):\n",
        "    mlp = MLPClassifier(**config)\n",
        "    mlp.fit(X_train, y_train)\n",
        "    y_pred = mlp.predict(X_test)\n",
        "    test_item = {\"config\":config, \"accuracy\":accuracy_score(y_test, y_pred)}\n",
        "    return test_item"
      ],
      "metadata": {
        "id": "bNUCnBBA-1WB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "global population\n",
        "\n",
        "config_ranges = {\n",
        "    \"hidden_layer_sizes\": [(100,), (50), (10, 10)],\n",
        "    \"max_iter\": [7],\n",
        "    \"alpha\": [1e-3, 1e-4, 1e-5],\n",
        "    \"solver\": [\"adam\", \"sgd\"],\n",
        "    \"learning_rate_init\": [0.05, 0.1, 0.15],\n",
        "    \"activation\": ['relu', 'logistic', 'tanh'],\n",
        "    \"verbose\": [0],\n",
        "    \"random_state\": [1]\n",
        "}\n",
        "numerical_keys = {\"alpha\", \"learning_rate_init\"}\n",
        "all_keys = list(config_ranges.keys())\n",
        "mutable_keys = [key for key in all_keys if len(config_ranges[key]) > 1]\n",
        "\n",
        "mutant_rate = 0.25\n",
        "max_population = 10\n",
        "generations = 7\n",
        "births_per_generation = 5\n",
        "tournament_size = 4\n",
        "population = []\n",
        "\n",
        "def sort_population():\n",
        "    global population\n",
        "    population = sorted(population, key=lambda item: -item[\"accuracy\"])\n",
        "\n",
        "def add_to_population(config):\n",
        "    result = run_configuration(config)\n",
        "    if result not in population:\n",
        "       population.insert(1, result)\n",
        "\n",
        "def random_tournament(ignore={}):\n",
        "    volunteers = [body for body in population if body != ignore]\n",
        "    return max(random.sample(volunteers, min(len(volunteers), tournament_size)), key=lambda body: body[\"accuracy\"])\n",
        "\n",
        "def reproduce(left_body, right_body):\n",
        "    new_config = left_body[\"config\"].copy()\n",
        "    for each_key in random.sample(all_keys, random.randint(0, len(all_keys))):\n",
        "        new_config[each_key] = right_body[\"config\"][each_key]\n",
        "    if random.uniform(0, 1) < mutant_rate:\n",
        "        mutation = random.choice(mutable_keys)\n",
        "        if mutation in numerical_keys:\n",
        "            new_config[mutation] *= random.uniform(0.8, 1.2)\n",
        "        else:\n",
        "            new_config[mutation] = random.choice([each for each in config_ranges[mutation] if each != new_config[mutation]])\n",
        "\n",
        "    return new_config\n",
        "\n",
        "def cull_population():\n",
        "    sort_population()\n",
        "    global population\n",
        "    population = population[:max_population]\n",
        "\n",
        "def init_population():\n",
        "    for _ in range(0, max_population):\n",
        "        new_config = {}\n",
        "        for each_key in config_ranges:\n",
        "            new_config[each_key] = random.choice(config_ranges[each_key])\n",
        "        add_to_population(new_config)\n",
        "\n",
        "# Filter out ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "init_population()\n",
        "\n",
        "for generation in range(0, generations + 1):\n",
        "    print(\"generation\", generation, \"population\", len(population), \"best\", max(population, key=lambda body: body[\"accuracy\"])[\"accuracy\"])\n",
        "    for _ in range(0, births_per_generation):\n",
        "        left_body = random_tournament()\n",
        "        right_body = random_tournament(left_body)\n",
        "        add_to_population(reproduce(left_body, right_body))\n",
        "    cull_population()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDtJQ-p32M6z",
        "outputId": "af91f60c-ebab-4e7f-e8ec-92aeffab1d97"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generation 0 population 10 best 0.8772\n",
            "generation 1 population 10 best 0.8773\n",
            "generation 2 population 10 best 0.8773\n",
            "generation 3 population 10 best 0.8775\n",
            "generation 4 population 10 best 0.8794\n",
            "generation 5 population 10 best 0.8794\n",
            "generation 6 population 10 best 0.8794\n",
            "generation 7 population 10 best 0.8798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for each_body in population: print(each_body)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2PjkXACpfYk",
        "outputId": "959047f2-bdac-4783-9f91-13fd66a1e23f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'config': {'hidden_layer_sizes': (100,), 'max_iter': 7, 'alpha': 0.0010062195987208915, 'solver': 'sgd', 'learning_rate_init': 0.05, 'activation': 'relu', 'verbose': 0, 'random_state': 1}, 'accuracy': 0.8798}\n",
            "{'config': {'hidden_layer_sizes': (100,), 'max_iter': 7, 'alpha': 0.001, 'solver': 'sgd', 'learning_rate_init': 0.05, 'activation': 'relu', 'verbose': 0, 'random_state': 1}, 'accuracy': 0.8794}\n",
            "{'config': {'hidden_layer_sizes': (100,), 'max_iter': 7, 'alpha': 0.0010062195987208915, 'solver': 'sgd', 'learning_rate_init': 0.05, 'activation': 'tanh', 'verbose': 0, 'random_state': 1}, 'accuracy': 0.8775}\n",
            "{'config': {'hidden_layer_sizes': (100,), 'max_iter': 7, 'alpha': 0.001, 'solver': 'sgd', 'learning_rate_init': 0.05, 'activation': 'tanh', 'verbose': 0, 'random_state': 1}, 'accuracy': 0.8773}\n",
            "{'config': {'hidden_layer_sizes': (100,), 'max_iter': 7, 'alpha': 0.001, 'solver': 'sgd', 'learning_rate_init': 0.056379950688487716, 'activation': 'relu', 'verbose': 0, 'random_state': 1}, 'accuracy': 0.8772}\n",
            "{'config': {'hidden_layer_sizes': 50, 'max_iter': 7, 'alpha': 0.001, 'solver': 'sgd', 'learning_rate_init': 0.05, 'activation': 'relu', 'verbose': 0, 'random_state': 1}, 'accuracy': 0.8772}\n",
            "{'config': {'hidden_layer_sizes': (100,), 'max_iter': 7, 'alpha': 0.0010948159282659347, 'solver': 'sgd', 'learning_rate_init': 0.05, 'activation': 'tanh', 'verbose': 0, 'random_state': 1}, 'accuracy': 0.8771}\n",
            "{'config': {'hidden_layer_sizes': (100,), 'max_iter': 7, 'alpha': 0.0001, 'solver': 'sgd', 'learning_rate_init': 0.05, 'activation': 'tanh', 'verbose': 0, 'random_state': 1}, 'accuracy': 0.8765}\n",
            "{'config': {'hidden_layer_sizes': (100,), 'max_iter': 7, 'alpha': 0.0001, 'solver': 'sgd', 'learning_rate_init': 0.05, 'activation': 'logistic', 'verbose': 0, 'random_state': 1}, 'accuracy': 0.8752}\n",
            "{'config': {'hidden_layer_sizes': 50, 'max_iter': 7, 'alpha': 0.0001, 'solver': 'sgd', 'learning_rate_init': 0.1, 'activation': 'logistic', 'verbose': 0, 'random_state': 1}, 'accuracy': 0.8745}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ado0qML40mzU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2yAGuuw06UBl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Fashion-MNIST image classification  using pytorch"
      ],
      "metadata": {
        "id": "a2qcKggmIH8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# scale to [0,1], add channel dimension -> (N, 1, 28, 28)\n",
        "X_train = (X_train.astype(\"float32\") / 255.0)[:, None, :, :]\n",
        "X_test  = (X_test.astype(\"float32\")  / 255.0)[:,  None, :, :]\n",
        "\n",
        "y_train = y_train.astype(np.int64)\n",
        "y_test  = y_test.astype(np.int64)\n",
        "\n",
        "# train/val split: last 10k of train as validation\n",
        "X_tr, X_val = X_train[:50000], X_train[50000:]\n",
        "y_tr, y_val = y_train[:50000], y_train[50000:]\n",
        "\n",
        "# wrap in PyTorch TensorDatasets and DataLoaders\n",
        "train_ds = TensorDataset(torch.from_numpy(X_tr),  torch.from_numpy(y_tr))\n",
        "val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False)\n",
        "\n",
        "# 2. Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "B9IQwhgcIVOl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# In colab, you should ``change runtime type'' to GPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# your code here"
      ],
      "metadata": {
        "id": "0REsDBunNmEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680b45ad-d9e4-400b-d7de-0ca9c46eeae1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define a Convolutional Neural Network (CNN) model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc = nn.Linear(32 * 7 * 7, 10) # 7x7 comes from the image size after pooling\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(x.size(0), -1) # Flatten the output for the fully connected layer\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN().to(device)"
      ],
      "metadata": {
        "id": "8R1DGSCZdOwq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5ff1abc",
        "outputId": "3451c195-d955-4cab-a632-d4c1029115ae"
      },
      "source": [
        "# 6. Evaluate the trained model on the test set\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader: # Evaluate on the test set\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 90.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e00cd7b",
        "outputId": "9f6f513a-e554-4985-a53c-dd4bea17d4e3"
      },
      "source": [
        "# 4. Implement the evaluation loop\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in val_loader: # Evaluate on the validation set\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Validation Accuracy: {accuracy:.2f}%')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 91.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef62ddfb",
        "outputId": "c79908e2-c1bd-44e7-affc-108cedd38ccf"
      },
      "source": [
        "# 3. Implement the training loop\n",
        "num_epochs = 10 # You can adjust this number\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train() # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.1089\n",
            "Epoch [2/10], Loss: 0.1094\n",
            "Epoch [3/10], Loss: 0.1058\n",
            "Epoch [4/10], Loss: 0.1060\n",
            "Epoch [5/10], Loss: 0.1040\n",
            "Epoch [6/10], Loss: 0.1007\n",
            "Epoch [7/10], Loss: 0.0999\n",
            "Epoch [8/10], Loss: 0.0995\n",
            "Epoch [9/10], Loss: 0.0990\n",
            "Epoch [10/10], Loss: 0.0968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c68fca49"
      },
      "source": [],
      "execution_count": 11,
      "outputs": []
    }
  ]
}